{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd\n",
    "from feast import FeatureStore\n",
    "from feast.dqm.profilers.ge_profiler import ge_profiler\n",
    "from great_expectations.core.expectation_suite import ExpectationSuite\n",
    "from great_expectations.dataset import PandasDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our feature store\n",
    "store = FeatureStore(repo_path=\"feature_repo/\")\n",
    "\n",
    "# Getting a saved dataset\n",
    "dataset = store.get_saved_dataset(name=\"driver_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolerance value for the mean\n",
    "DELTA = 0.1\n",
    "\n",
    "# Creating a profiler function\n",
    "@ge_profiler\n",
    "def stats_profiler(ds: PandasDataset) -> ExpectationSuite:\n",
    "    # DEFINING MINIMUM AND MAXIMUM\n",
    "    # EXPECTED VALUES\n",
    "\n",
    "    # Getting min and max values for avg_daily_trips\n",
    "    observed_min = ds[\"avg_daily_trips\"].min()\n",
    "    observed_max = ds[\"avg_daily_trips\"].max()\n",
    "\n",
    "    # Setting the expected min and max values\n",
    "    ds.expect_column_values_to_be_between(\n",
    "        column=\"avg_daily_trips\",\n",
    "        mostly=0.99,\n",
    "        min_value=observed_min,\n",
    "        max_value=observed_max       \n",
    "    )\n",
    "\n",
    "    # DEFINING EXPECTED AVERAGE\n",
    "\n",
    "    # Getting the average of avg_daily_trips\n",
    "    observed_mean = ds[\"avg_daily_trips\"].mean()\n",
    "    \n",
    "    # Setting the expected range\n",
    "    ds.expect_column_mean_to_be_between(\n",
    "        column=\"avg_daily_trips\",        \n",
    "        min_value=observed_mean * (1 - DELTA),\n",
    "        max_value=observed_mean * (1 + DELTA)\n",
    "    )\n",
    "\n",
    "    # Retrieving comparison results\n",
    "    return ds.get_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<GEProfile with expectations: [\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "    \"meta\": {},\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_daily_trips\",\n",
       "      \"mostly\": 0.99,\n",
       "      \"min_value\": 2,\n",
       "      \"max_value\": 998\n",
       "    }\n",
       "  },\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_mean_to_be_between\",\n",
       "    \"meta\": {},\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_daily_trips\",\n",
       "      \"min_value\": 435.62050632911394,\n",
       "      \"max_value\": 532.4250632911393\n",
       "    }\n",
       "  }\n",
       "]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the expectation function\n",
    "dataset.get_profile(profiler=stats_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a reference for validation\n",
    "validation_reference = dataset.as_reference(\"driver_stats_validation_reference\",profiler=stats_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an entity DataFrame with timestamps\n",
    "timestamps = pd.date_range(\n",
    "    start=\"2021-09-05\",    \n",
    "    end=\"2021-09-06\",     \n",
    "    freq='H').to_frame(name=\"event_timestamp\", index=False)\n",
    "\n",
    "# Creating patient IDs for the entity DataFrame\n",
    "driver_ids = pd.DataFrame(data=[1001, 1002, 1003, 1004, 1005], \n",
    "                          columns=[\"driver_id\"])\n",
    "\n",
    "# Creating the cartesian product of our timestamps and entities \n",
    "entity_df = timestamps.merge(right=driver_ids, \n",
    "                             how=\"cross\")\n",
    "\n",
    "# Getting the indicated historical features\n",
    "# and joining them with our entity DataFrame\n",
    "historical_features = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"driver_stats_fv:conv_rate\",\n",
    "        \"driver_stats_fv:acc_rate\",\n",
    "        \"driver_stats_fv:avg_daily_trips\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationFailed",
     "evalue": "[\n  {\n    \"exception_info\": {\n      \"raised_exception\": false,\n      \"exception_message\": null,\n      \"exception_traceback\": null\n    },\n    \"meta\": {},\n    \"expectation_config\": {\n      \"expectation_type\": \"expect_column_values_to_be_between\",\n      \"meta\": {},\n      \"kwargs\": {\n        \"column\": \"avg_daily_trips\",\n        \"mostly\": 0.99,\n        \"min_value\": 2,\n        \"max_value\": 998,\n        \"result_format\": \"COMPLETE\"\n      }\n    },\n    \"result\": {\n      \"element_count\": 125,\n      \"missing_count\": 0,\n      \"missing_percent\": 0.0,\n      \"unexpected_count\": 2,\n      \"unexpected_percent\": 1.6,\n      \"unexpected_percent_total\": 1.6,\n      \"unexpected_percent_nonmissing\": 1.6,\n      \"partial_unexpected_list\": [\n        0,\n        1\n      ],\n      \"partial_unexpected_index_list\": [\n        60,\n        71\n      ],\n      \"partial_unexpected_counts\": [\n        {\n          \"value\": 0,\n          \"count\": 1\n        },\n        {\n          \"value\": 1,\n          \"count\": 1\n        }\n      ],\n      \"unexpected_list\": [\n        0,\n        1\n      ],\n      \"unexpected_index_list\": [\n        60,\n        71\n      ]\n    },\n    \"success\": false\n  }\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationFailed\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Converting the RetrievalJob to a DataFrame and validating it against our reference dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m _ \u001b[39m=\u001b[39m historical_features\u001b[39m.\u001b[39;49mto_df(validation_reference\u001b[39m=\u001b[39;49mvalidation_reference)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/feast/infra/offline_stores/offline_store.py:99\u001b[0m, in \u001b[0;36mRetrievalJob.to_df\u001b[0;34m(self, validation_reference)\u001b[0m\n\u001b[1;32m     97\u001b[0m     validation_result \u001b[39m=\u001b[39m validation_reference\u001b[39m.\u001b[39mprofile\u001b[39m.\u001b[39mvalidate(features_df)\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m validation_result\u001b[39m.\u001b[39mis_success:\n\u001b[0;32m---> 99\u001b[0m         \u001b[39mraise\u001b[39;00m ValidationFailed(validation_result)\n\u001b[1;32m    101\u001b[0m \u001b[39mreturn\u001b[39;00m features_df\n",
      "\u001b[0;31mValidationFailed\u001b[0m: [\n  {\n    \"exception_info\": {\n      \"raised_exception\": false,\n      \"exception_message\": null,\n      \"exception_traceback\": null\n    },\n    \"meta\": {},\n    \"expectation_config\": {\n      \"expectation_type\": \"expect_column_values_to_be_between\",\n      \"meta\": {},\n      \"kwargs\": {\n        \"column\": \"avg_daily_trips\",\n        \"mostly\": 0.99,\n        \"min_value\": 2,\n        \"max_value\": 998,\n        \"result_format\": \"COMPLETE\"\n      }\n    },\n    \"result\": {\n      \"element_count\": 125,\n      \"missing_count\": 0,\n      \"missing_percent\": 0.0,\n      \"unexpected_count\": 2,\n      \"unexpected_percent\": 1.6,\n      \"unexpected_percent_total\": 1.6,\n      \"unexpected_percent_nonmissing\": 1.6,\n      \"partial_unexpected_list\": [\n        0,\n        1\n      ],\n      \"partial_unexpected_index_list\": [\n        60,\n        71\n      ],\n      \"partial_unexpected_counts\": [\n        {\n          \"value\": 0,\n          \"count\": 1\n        },\n        {\n          \"value\": 1,\n          \"count\": 1\n        }\n      ],\n      \"unexpected_list\": [\n        0,\n        1\n      ],\n      \"unexpected_index_list\": [\n        60,\n        71\n      ]\n    },\n    \"success\": false\n  }\n]"
     ]
    }
   ],
   "source": [
    "# Converting the RetrievalJob to a DataFrame and validating it against our reference dataset\n",
    "_ = historical_features.to_df(validation_reference=validation_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an entity DataFrame with timestamps\n",
    "timestamps = pd.date_range(\n",
    "    start=\"2021-09-05\",    \n",
    "    end=\"2021-09-15\",     \n",
    "    freq='H').to_frame(name=\"event_timestamp\", index=False)\n",
    "\n",
    "# Creating the cartesian product of our timestamps and entities \n",
    "entity_df = timestamps.merge(right=driver_ids, \n",
    "                             how=\"cross\")\n",
    "\n",
    "# Getting the indicated historical features\n",
    "# and joining them with our entity DataFrame\n",
    "historical_features = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"driver_stats_fv:conv_rate\",\n",
    "        \"driver_stats_fv:acc_rate\",\n",
    "        \"driver_stats_fv:avg_daily_trips\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the RetrievalJob to a DataFrame and validating it against our reference dataset\n",
    "_ = historical_features.to_df(validation_reference=validation_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<GEProfile with expectations: [\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "    \"meta\": {},\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_daily_trips\",\n",
       "      \"mostly\": 0.99,\n",
       "      \"min_value\": 11,\n",
       "      \"max_value\": 982\n",
       "    }\n",
       "  },\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_mean_to_be_between\",\n",
       "    \"meta\": {},\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_daily_trips\",\n",
       "      \"min_value\": 401.83291139240504,\n",
       "      \"max_value\": 491.12911392405067\n",
       "    }\n",
       "  }\n",
       "]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a saved dataset\n",
    "dataset_1001 = store.get_saved_dataset(name='driver_stats_1001')\n",
    "\n",
    "# Checking the expectation function\n",
    "dataset_1001.get_profile(profiler=stats_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an entity DataFrame with timestamps\n",
    "timestamps = pd.date_range(\n",
    "    start=\"2021-09-05\",    \n",
    "    end=\"2021-09-15\",     \n",
    "    freq='H').to_frame(name=\"event_timestamp\", index=False)\n",
    "\n",
    "# Creating patient IDs for the entity DataFrame\n",
    "driver_id = pd.DataFrame([1001], columns=[\"driver_id\"])\n",
    "\n",
    "# Creating the cartesian product of our timestamps and entities \n",
    "entity_df = timestamps.merge(right=driver_id, how=\"cross\")\n",
    "\n",
    "# Getting the indicated historical features\n",
    "# and joining them with our entity DataFrame\n",
    "historical_features = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"driver_stats_fv:conv_rate\",\n",
    "        \"driver_stats_fv:acc_rate\",\n",
    "        \"driver_stats_fv:avg_daily_trips\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the RetrievalJob to a DataFrame and validating it against our reference dataset\n",
    "_ = historical_features.to_df(validation_reference=validation_reference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
